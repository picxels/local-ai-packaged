services:
  training-system-api:
    container_name: training-system-api
    build:
      context: .
      dockerfile: Dockerfile.api
    ports:
      - "9099:9099"
    volumes:
      # When running from TrainingSystem directory, use relative paths correctly
      - ./data:/app/data
      - ./logs:/app/logs
      - ./cache:/app/cache
      - ./models:/app/models
      # The correct mount for the code (current directory is already trainer)
      - .:/app
    environment:
      # Core service settings
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=all
      - PYTHONPATH=/app
      
      # API settings
      - API_CORS_ORIGINS=*
      - API_CORS_METHODS=GET,POST,PUT,DELETE,OPTIONS
      
      # Database settings - use environment variables or defaults
      - SUPABASE_URL=${SUPABASE_URL:-http://supabase-kong:8000}
      - SUPABASE_KEY=${SERVICE_ROLE_KEY:-eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.ewogICJyb2xlIjogInNlcnZpY2Vfcm9sZSIsCiAgImlzcyI6ICJzdXBhYmFzZSIsCiAgImlhdCI6IDE3NDIwNzYwMDAsCiAgImV4cCI6IDE4OTk4NDI0MDAKfQ.w_rVKJxfPSkxh5FckwWBp6jzW-WjgDzpY0UdiNN-sgk}
      - SUPABASE_SERVICE_TOKEN=${SERVICE_ROLE_KEY:-eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.ewogICJyb2xlIjogInNlcnZpY2Vfcm9sZSIsCiAgImlzcyI6ICJzdXBhYmFzZSIsCiAgImlhdCI6IDE3NDIwNzYwMDAsCiAgImV4cCI6IDE4OTk4NDI0MDAKfQ.w_rVKJxfPSkxh5FckwWBp6jzW-WjgDzpY0UdiNN-sgk}
      - SUPABASE_ANON_TOKEN=${ANON_KEY:-eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.ewogICJyb2xlIjogImFub24iLAogICJpc3MiOiAic3VwYWJhc2UiLAogICJpYXQiOiAxNzQyMDc2MDAwLAogICJleHAiOiAxODk5ODQyNDAwCn0.TjlLQc7KjOQEOkkovhPEQywwozyZ8I16ZSAeSqjcMGc}
      - QDRANT_PORT=6333
      - QDRANT_API_KEY=${QDRANT_API_KEY:-}
      - QDRANT_COLLECTION=${QDRANT_COLLECTION:-training_documents}
      
      # Model settings
      - LLM_MODEL=${LLM_MODEL:-llama2}
      - LLM_TEMPERATURE=${LLM_TEMPERATURE:-0.7}
      - LLM_MAX_TOKENS=${LLM_MAX_TOKENS:-2000}
      - MODEL_NAME=${MODEL_NAME:-gemma:27b-q4}
      - MODEL_EMBEDDING_NAME=${MODEL_EMBEDDING_NAME:-nomic-embed-text}
      - MAX_SEQUENCE_LENGTH=${MAX_SEQUENCE_LENGTH:-4096}
      - TRAINING_BATCH_SIZE=${TRAINING_BATCH_SIZE:-4}
      - MAX_WORKERS=${MAX_WORKERS:-2}
      
      # Document processing
      - MAX_DOCUMENT_SIZE=10000000
      - BATCH_SIZE=5
      
      # External services - use localhost when running standalone
      - OLLAMA_BASE_URL=${OLLAMA_BASE_URL:-http://host.docker.internal:11434}
      - QDRANT_URL=${QDRANT_URL:-http://host.docker.internal:6333}
      - REDIS_URL=${REDIS_URL:-redis://host.docker.internal:6379}
      - FIRECRAWL_API_URL=${FIRECRAWL_API_URL:-http://host.docker.internal:3003}
      
      # Additional settings
      - USE_DB_AUTHENTICATION=false
      - TEST_API_KEY=fc-ctf63ca1786042429794932425be0x597

    # Use host networking so the container can connect to services on the host
    extra_hosts:
      - "host.docker.internal:host-gateway"
      
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9099/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 20s
    command: /bin/bash